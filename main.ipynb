{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!git clone https://github.com/longday1102/finetune-VietAI.git","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","scrolled":true,"execution":{"iopub.status.busy":"2023-09-22T16:47:16.503674Z","iopub.execute_input":"2023-09-22T16:47:16.506848Z","iopub.status.idle":"2023-09-22T16:47:18.925177Z","shell.execute_reply.started":"2023-09-22T16:47:16.506793Z","shell.execute_reply":"2023-09-22T16:47:18.923720Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Cloning into 'finetune-VietAI'...\nremote: Enumerating objects: 28, done.\u001b[K\nremote: Counting objects: 100% (28/28), done.\u001b[K\nremote: Compressing objects: 100% (28/28), done.\u001b[K\nremote: Total 28 (delta 15), reused 0 (delta 0), pack-reused 0\u001b[K\nReceiving objects: 100% (28/28), 8.52 KiB | 2.13 MiB/s, done.\nResolving deltas: 100% (15/15), done.\n","output_type":"stream"}]},{"cell_type":"code","source":"%cd /kaggle/working/finetune-VietAI\n!pip install --upgrade -r requirements.txt","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2023-09-22T16:47:18.931093Z","iopub.execute_input":"2023-09-22T16:47:18.931986Z","iopub.status.idle":"2023-09-22T16:47:54.402051Z","shell.execute_reply.started":"2023-09-22T16:47:18.931935Z","shell.execute_reply":"2023-09-22T16:47:54.400557Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"/kaggle/working/finetune-VietAI\nRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 1)) (4.33.0)\nCollecting transformers (from -r requirements.txt (line 1))\n  Downloading transformers-4.33.2-py3-none-any.whl (7.6 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m37.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting peft (from -r requirements.txt (line 2))\n  Downloading peft-0.5.0-py3-none-any.whl (85 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.6/85.6 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 3)) (2.1.0)\nCollecting datasets (from -r requirements.txt (line 3))\n  Downloading datasets-2.14.5-py3-none-any.whl (519 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m519.6/519.6 kB\u001b[0m \u001b[31m29.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 4)) (0.22.0)\nCollecting accelerate (from -r requirements.txt (line 4))\n  Downloading accelerate-0.23.0-py3-none-any.whl (258 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m258.1/258.1 kB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting bitsandbytes (from -r requirements.txt (line 5))\n  Downloading bitsandbytes-0.41.1-py3-none-any.whl (92.6 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.6/92.6 MB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers->-r requirements.txt (line 1)) (3.12.2)\nRequirement already satisfied: huggingface-hub<1.0,>=0.15.1 in /opt/conda/lib/python3.10/site-packages (from transformers->-r requirements.txt (line 1)) (0.16.4)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers->-r requirements.txt (line 1)) (1.23.5)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers->-r requirements.txt (line 1)) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers->-r requirements.txt (line 1)) (6.0)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers->-r requirements.txt (line 1)) (2023.6.3)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers->-r requirements.txt (line 1)) (2.31.0)\nRequirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.10/site-packages (from transformers->-r requirements.txt (line 1)) (0.13.3)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers->-r requirements.txt (line 1)) (0.3.3)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers->-r requirements.txt (line 1)) (4.66.1)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from peft->-r requirements.txt (line 2)) (5.9.3)\nRequirement already satisfied: torch>=1.13.0 in /opt/conda/lib/python3.10/site-packages (from peft->-r requirements.txt (line 2)) (2.0.0)\nRequirement already satisfied: pyarrow>=8.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets->-r requirements.txt (line 3)) (11.0.0)\nRequirement already satisfied: dill<0.3.8,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets->-r requirements.txt (line 3)) (0.3.7)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets->-r requirements.txt (line 3)) (2.0.2)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets->-r requirements.txt (line 3)) (3.3.0)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets->-r requirements.txt (line 3)) (0.70.15)\nCollecting fsspec[http]<2023.9.0,>=2023.1.0 (from datasets->-r requirements.txt (line 3))\n  Downloading fsspec-2023.6.0-py3-none-any.whl (163 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.8/163.8 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets->-r requirements.txt (line 3)) (3.8.4)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->-r requirements.txt (line 3)) (23.1.0)\nRequirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->-r requirements.txt (line 3)) (3.1.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->-r requirements.txt (line 3)) (6.0.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->-r requirements.txt (line 3)) (4.0.2)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->-r requirements.txt (line 3)) (1.9.2)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->-r requirements.txt (line 3)) (1.3.3)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->-r requirements.txt (line 3)) (1.3.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.15.1->transformers->-r requirements.txt (line 1)) (4.6.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers->-r requirements.txt (line 1)) (3.0.9)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers->-r requirements.txt (line 1)) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers->-r requirements.txt (line 1)) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers->-r requirements.txt (line 1)) (2023.7.22)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft->-r requirements.txt (line 2)) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft->-r requirements.txt (line 2)) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft->-r requirements.txt (line 2)) (3.1.2)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->-r requirements.txt (line 3)) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->-r requirements.txt (line 3)) (2023.3)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->-r requirements.txt (line 3)) (2023.3)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets->-r requirements.txt (line 3)) (1.16.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->peft->-r requirements.txt (line 2)) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.13.0->peft->-r requirements.txt (line 2)) (1.3.0)\nInstalling collected packages: bitsandbytes, fsspec, transformers, accelerate, peft, datasets\n  Attempting uninstall: fsspec\n    Found existing installation: fsspec 2023.9.0\n    Uninstalling fsspec-2023.9.0:\n      Successfully uninstalled fsspec-2023.9.0\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.33.0\n    Uninstalling transformers-4.33.0:\n      Successfully uninstalled transformers-4.33.0\n  Attempting uninstall: accelerate\n    Found existing installation: accelerate 0.22.0\n    Uninstalling accelerate-0.22.0:\n      Successfully uninstalled accelerate-0.22.0\n  Attempting uninstall: datasets\n    Found existing installation: datasets 2.1.0\n    Uninstalling datasets-2.1.0:\n      Successfully uninstalled datasets-2.1.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ncuml 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ndask-cudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ncudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.0.2 which is incompatible.\ncudf 23.8.0 requires protobuf<5,>=4.21, but you have protobuf 3.20.3 which is incompatible.\ncuml 23.8.0 requires dask==2023.7.1, but you have dask 2023.9.0 which is incompatible.\ndask-cuda 23.8.0 requires dask==2023.7.1, but you have dask 2023.9.0 which is incompatible.\ndask-cuda 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.0.2 which is incompatible.\ndask-cudf 23.8.0 requires dask==2023.7.1, but you have dask 2023.9.0 which is incompatible.\ndask-cudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.0.2 which is incompatible.\ndistributed 2023.7.1 requires dask==2023.7.1, but you have dask 2023.9.0 which is incompatible.\nraft-dask 23.8.0 requires dask==2023.7.1, but you have dask 2023.9.0 which is incompatible.\ns3fs 2023.9.0 requires fsspec==2023.9.0, but you have fsspec 2023.6.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed accelerate-0.23.0 bitsandbytes-0.41.1 datasets-2.14.5 fsspec-2023.6.0 peft-0.5.0 transformers-4.33.2\n","output_type":"stream"}]},{"cell_type":"code","source":"from train import Trainer","metadata":{"execution":{"iopub.status.busy":"2023-09-22T16:10:13.340262Z","iopub.execute_input":"2023-09-22T16:10:13.340642Z","iopub.status.idle":"2023-09-22T16:10:27.065350Z","shell.execute_reply.started":"2023-09-22T16:10:13.340608Z","shell.execute_reply":"2023-09-22T16:10:27.064398Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"code","source":"trainer = Trainer(\n    model_name = \"bigscience/bloom-560m\",\n    dataset_name = \"MBZUAI/Bactrian-X\",\n    num_epochs = 1)","metadata":{"execution":{"iopub.status.busy":"2023-09-22T16:11:06.792330Z","iopub.execute_input":"2023-09-22T16:11:06.792714Z","iopub.status.idle":"2023-09-22T16:11:06.798534Z","shell.execute_reply.started":"2023-09-22T16:11:06.792684Z","shell.execute_reply":"2023-09-22T16:11:06.797075Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"trainer.train()","metadata":{"execution":{"iopub.status.busy":"2023-09-22T16:11:13.963291Z","iopub.execute_input":"2023-09-22T16:11:13.963665Z","iopub.status.idle":"2023-09-22T16:21:31.495162Z","shell.execute_reply.started":"2023-09-22T16:11:13.963636Z","shell.execute_reply":"2023-09-22T16:21:31.493997Z"},"trusted":true},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading (…)lve/main/config.json:   0%|          | 0.00/693 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"19964a8ecd3c45b9b66964d2f5399b58"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)okenizer_config.json:   0%|          | 0.00/222 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"79cc710a05d24130b4dc935a3d5c1fff"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading tokenizer.json:   0%|          | 0.00/14.5M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c18be92902c0426b9031b37d44e9e0a2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)cial_tokens_map.json:   0%|          | 0.00/85.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dc9819796c304d9d91c8522c42a42723"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading model.safetensors:   0%|          | 0.00/1.12G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"503bab71987949fa8c1287610b7f2caf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/2.26k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"738acbfb06a442ad958ff433719351fa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading readme:   0%|          | 0.00/13.5k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0e981dbc7ce24a0d88ddd88ce064cb12"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/20.9M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"12167ca98df14ca683d9013e60ed6079"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"061b23f857fd48a9aaeeff639645eea2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map (num_proc=13):   0%|          | 0/2850 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"87ff6f5f90234ae8ad55e0aec10cea1d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map (num_proc=13):   0%|          | 0/150 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f5bc3d6e0a334be996f5e064121d7e7c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/2850 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"95a17ee6fe2544d39c73680f0ccb3c2e"}},"metadata":{}},{"name":"stderr","text":"You're using a BloomTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 1 -- step: 50 -- avg_train_loss: 2.2138019824028015 -- avg_train_ppl: 9.150440154091957\nEpoch: 1 -- step: 100 -- avg_train_loss: 2.055752170085907 -- avg_train_ppl: 7.81271215150069\nEpoch: 1 -- step: 150 -- avg_train_loss: 2.053326789538066 -- avg_train_ppl: 7.793786311881745\nEpoch: 1 -- step: 200 -- avg_train_loss: 2.05068019926548 -- avg_train_ppl: 7.773186624332554\nEpoch: 1 -- step: 250 -- avg_train_loss: 2.05937100982666 -- avg_train_ppl: 7.841036324127256\nEpoch: 1 -- step: 300 -- avg_train_loss: 2.0854676286379497 -- avg_train_ppl: 8.048354242773987\nEpoch: 1 -- step: 350 -- avg_train_loss: 2.0800336064611162 -- avg_train_ppl: 8.004737920689829\nEpoch: 1 -- step: 400 -- avg_train_loss: 2.047515414357185 -- avg_train_ppl: 7.74862504716932\nEpoch: 1 -- step: 450 -- avg_train_loss: 2.0247840371396806 -- avg_train_ppl: 7.574474962709171\nEpoch: 1 -- step: 500 -- avg_train_loss: 2.006552368760109 -- avg_train_ppl: 7.437630885446333\nEpoch: 1 -- step: 550 -- avg_train_loss: 1.9888954345746475 -- avg_train_ppl: 7.307457737717596\nEpoch: 1 -- step: 600 -- avg_train_loss: 1.9759048158923784 -- avg_train_ppl: 7.213143268703713\nEpoch: 1 -- step: 650 -- avg_train_loss: 1.9636437736107752 -- avg_train_ppl: 7.125242592254236\nEpoch: 1 -- step: 700 -- avg_train_loss: 1.9568421710389001 -- avg_train_ppl: 7.076943964148399\nEpoch: 1 -- step: 750 -- avg_train_loss: 1.9441576681931814 -- avg_train_ppl: 6.987743376850696\nEpoch: 1 -- step: 800 -- avg_train_loss: 1.931551028713584 -- avg_train_ppl: 6.900204361087832\nEpoch: 1 -- step: 850 -- avg_train_loss: 1.9293701653620776 -- avg_train_ppl: 6.885172355611644\nEpoch: 1 -- step: 900 -- avg_train_loss: 1.925059534576204 -- avg_train_ppl: 6.855556796418636\nEpoch: 1 -- step: 950 -- avg_train_loss: 1.919366779703843 -- avg_train_ppl: 6.816640667153\nEpoch: 1 -- step: 1000 -- avg_train_loss: 1.915274987757206 -- avg_train_ppl: 6.78880537870919\nEpoch: 1 -- step: 1050 -- avg_train_loss: 1.9082514175914582 -- avg_train_ppl: 6.741290784161121\nEpoch: 1 -- step: 1100 -- avg_train_loss: 1.9053673992915587 -- avg_train_ppl: 6.721876786792924\nEpoch: 1 -- step: 1150 -- avg_train_loss: 1.8996253835636636 -- avg_train_ppl: 6.6833902654117745\nEpoch: 1 -- step: 1200 -- avg_train_loss: 1.8937596111992996 -- avg_train_ppl: 6.644301773667325\nEpoch: 1 -- step: 1250 -- avg_train_loss: 1.8858849221229552 -- avg_train_ppl: 6.592185432376102\nEpoch: 1 -- step: 1300 -- avg_train_loss: 1.8844871380466681 -- avg_train_ppl: 6.582977417458326\nEpoch: 1 -- step: 1350 -- avg_train_loss: 1.8804528359792851 -- avg_train_ppl: 6.556473197016849\nEpoch: 1 -- step: 1400 -- avg_train_loss: 1.8745106504431792 -- avg_train_ppl: 6.517628941003551\nEpoch: 1 -- step: 1450 -- avg_train_loss: 1.8718450370533712 -- avg_train_ppl: 6.50027859695688\nEpoch: 1 -- step: 1500 -- avg_train_loss: 1.8655673535466195 -- avg_train_ppl: 6.4595997233601725\nEpoch: 1 -- step: 1550 -- avg_train_loss: 1.8572472024925293 -- avg_train_ppl: 6.406077841736375\nEpoch: 1 -- step: 1600 -- avg_train_loss: 1.851683930847794 -- avg_train_ppl: 6.370538040971399\nEpoch: 1 -- step: 1650 -- avg_train_loss: 1.8473546441576698 -- avg_train_ppl: 6.343017769976877\nEpoch: 1 -- step: 1700 -- avg_train_loss: 1.8406352802409844 -- avg_train_ppl: 6.300539598221146\nEpoch: 1 -- step: 1750 -- avg_train_loss: 1.8373034101384027 -- avg_train_ppl: 6.279581952169043\nEpoch: 1 -- step: 1800 -- avg_train_loss: 1.8308072086340852 -- avg_train_ppl: 6.238920737161913\nEpoch: 1 -- step: 1850 -- avg_train_loss: 1.822107656018154 -- avg_train_ppl: 6.184880322482225\nEpoch: 1 -- step: 1900 -- avg_train_loss: 1.8198453474201655 -- avg_train_ppl: 6.170904029855567\nEpoch: 1 -- step: 1950 -- avg_train_loss: 1.8171122308113636 -- avg_train_ppl: 6.154061256676326\nEpoch: 1 -- step: 2000 -- avg_train_loss: 1.8149915163367987 -- avg_train_ppl: 6.14102407884395\nEpoch: 1 -- step: 2050 -- avg_train_loss: 1.8110427411445758 -- avg_train_ppl: 6.11682237030745\nEpoch: 1 -- step: 2100 -- avg_train_loss: 1.806893386003517 -- avg_train_ppl: 6.091494086321016\nEpoch: 1 -- step: 2150 -- avg_train_loss: 1.7996248771562133 -- avg_train_ppl: 6.047378529043539\nEpoch: 1 -- step: 2200 -- avg_train_loss: 1.7950601100244306 -- avg_train_ppl: 6.019836563454883\nEpoch: 1 -- step: 2250 -- avg_train_loss: 1.7928769282632404 -- avg_train_ppl: 6.006708501750976\nEpoch: 1 -- step: 2300 -- avg_train_loss: 1.7897312482414038 -- avg_train_ppl: 5.987843006781981\nEpoch: 1 -- step: 2350 -- avg_train_loss: 1.784275667426434 -- avg_train_ppl: 5.95526479269407\nEpoch: 1 -- step: 2400 -- avg_train_loss: 1.7782722680643201 -- avg_train_ppl: 5.919620061669472\nEpoch: 1 -- step: 2450 -- avg_train_loss: 1.7737074119825753 -- avg_train_ppl: 5.892659430546735\nEpoch: 1 -- step: 2500 -- avg_train_loss: 1.7721791268706322 -- avg_train_ppl: 5.883660644975791\nEpoch: 1 -- step: 2550 -- avg_train_loss: 1.7704984623427484 -- avg_train_ppl: 5.873780490174179\nEpoch: 1 -- step: 2600 -- avg_train_loss: 1.7661134117727095 -- avg_train_ppl: 5.848080055721911\nEpoch: 1 -- step: 2650 -- avg_train_loss: 1.7621322600684075 -- avg_train_ppl: 5.82484424517435\nEpoch: 1 -- step: 2700 -- avg_train_loss: 1.7589110690686438 -- avg_train_ppl: 5.806111496395345\nEpoch: 1 -- step: 2750 -- avg_train_loss: 1.755195137554949 -- avg_train_ppl: 5.784576419928464\nEpoch: 1 -- step: 2800 -- avg_train_loss: 1.7503623682154077 -- avg_train_ppl: 5.7566883389739765\nEpoch: 1 -- step: 2850 -- avg_train_loss: 1.7473450670848814 -- avg_train_ppl: 5.739344855155443\nEvaluating..............................\nEpoch: 1 -- avg_train_loss: 1.7473450670848814 -- avg_val_loss: 1.5667024890581767 -- avg_train_ppl: 5.739344855155443 -- avg_val_ppl: 4.790824322795064\n================================================ End of epoch 1 ================================================\nSaving..........\n****************** Save successfully ******************\n","output_type":"stream"}]},{"cell_type":"code","source":"from inference import Inference","metadata":{"execution":{"iopub.status.busy":"2023-09-22T16:47:54.403859Z","iopub.execute_input":"2023-09-22T16:47:54.404309Z","iopub.status.idle":"2023-09-22T16:48:09.092249Z","shell.execute_reply.started":"2023-09-22T16:47:54.404259Z","shell.execute_reply":"2023-09-22T16:48:09.091058Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"code","source":"infer = Inference(\n    model_name = \"bigscience/bloom-560m\",\n    checkpoint = \"/kaggle/input/bloom-cp/bloom-560m.checkpoint\",\n    )","metadata":{"execution":{"iopub.status.busy":"2023-09-22T16:48:09.094935Z","iopub.execute_input":"2023-09-22T16:48:09.095759Z","iopub.status.idle":"2023-09-22T16:48:51.840822Z","shell.execute_reply.started":"2023-09-22T16:48:09.095715Z","shell.execute_reply":"2023-09-22T16:48:51.839667Z"},"trusted":true},"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading (…)lve/main/config.json:   0%|          | 0.00/693 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5a53f6ff68e149f6ad4f24a3715587ee"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading model.safetensors:   0%|          | 0.00/1.12G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e9c7832e3e784b1d882a49f9abfa50a1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)okenizer_config.json:   0%|          | 0.00/222 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9d9b911953c9457a830da69f7ee38aed"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading tokenizer.json:   0%|          | 0.00/14.5M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"41b097008c6c4852b18ed2be4f1d3b9d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)cial_tokens_map.json:   0%|          | 0.00/85.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4d44ae5831a34e649cc1d6c48809a1d8"}},"metadata":{}}]},{"cell_type":"code","source":"infer.get_answer(\n    instruction = \"Hãy nêu những lợi ích của việc uống cà phê\",\n    input = \"\",\n    )","metadata":{"execution":{"iopub.status.busy":"2023-09-22T16:50:20.053387Z","iopub.execute_input":"2023-09-22T16:50:20.053789Z","iopub.status.idle":"2023-09-22T16:50:27.778071Z","shell.execute_reply.started":"2023-09-22T16:50:20.053756Z","shell.execute_reply":"2023-09-22T16:50:27.776564Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"'1. Tăng cường sức khỏe tâm thần: Cà phê chứa nhiều chất chống oxy hóa và flavonoid, giúp tăng cường hệ thống miễn dịch và tăng cường sức đề kháng của cơ thể.\\n\\n2. Giảm cân: Cà phê có khả năng giảm cân hiệu quả, giúp cơ thể săn chắc hơn.\\n\\n3. Nâng cao sức khỏe tim mạch: Sử dụng cà phê thường xuyên có thể giúp cải thiện tim mạch và giảm nguy cơ mắc các bệnh tim mạch.\\n\\n4. Nỗ lực tăng cường tinh thần: Các hoạt động như đọc sách, đọc truyện tranh, vẽ tranh, tham gia các hoạt động nghệ thuật, hoặc tham gia vào các cuộc thi thể thao đều có lợi cho sức khỏe tinh thần.\\n\\n5. Giúp giảm căng thẳng và giảm lo âu: Các loại cà phê như arabica, robusta, arabica hoặc arabica arabica đều có thể được sử dụng như một loại thuốc giảm stress, giúp giảm căng và lo âu.'"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}